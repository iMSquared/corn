_target_: pkm.models.rl.net.point_patch_v2.PointPatchV2FeatNet.Config

dim_in: [512, 3]
dim_out: 256 # == encoder_channel x num_query?
keys: []
ctx_dim: 0
num_query: 1
patch_size: 32
encoder_channel: 256

encoder:
  _target_ : pkm.models.cloud.point_mae.PointMAEEncoder.Config
  layer:
    _target_ : pkm.models.cloud.point_mae.PointMAELayer.Config
    attention:
      _target_: pkm.models.cloud.point_mae.PointMAEAttention.Config
      self_attn:
        _target_: pkm.models.cloud.point_mae.PointMAESelfAttention.Config
        hidden_size: 256
        num_attention_heads: 4
        qkv_bias: true
        attention_probs_dropout_prob: 0.0
      output:
        _target_: pkm.models.cloud.point_mae.PointMAESelfOutput.Config
        hidden_size: 256
        hidden_dropout_prob: 0.0
    intermediate:
      _target_: pkm.models.cloud.point_mae.PointMAEIntermediate.Config
      hidden_size: 256
      intermediate_size: 128
      hidden_act: gelu
    output:
      _target_: pkm.models.cloud.point_mae.PointMAEOutput.Config
      intermediate_size: 128
      hidden_size: 256
      hidden_dropout_prob: 0.0
    hidden_size: 256
    layer_norm_eps: 1.0e-06
  num_hidden_layers: 4

patch_type: fps
patch_encoder_type: knn
pos_embed_type: mlp

p_drop: 0.0
patch_overlap: 1.0

ckpt: null
